"""
Gemini API service for chart analysis
"""

import logging
import io
import base64
from typing import Optional, Dict, Any
import os

try:
    import requests
except ImportError:
    requests = None

logger = logging.getLogger(__name__)


class GeminiService:
    """Service for analyzing charts using Gemini API"""
    
    def __init__(self, api_key: Optional[str] = None):
        """
        Initialize Gemini service
        
        Args:
            api_key: Google AI Studio API key for Gemini
        """
        self.client = None
        self.api_key = api_key or os.getenv('GEMINI_API_KEY')
        self.api_url = "https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash:generateContent"
        
        # –¶–µ–Ω—Ç—Ä–∞–ª–∏–∑–æ–≤–∞–Ω–Ω—ã–µ –ø—Ä–æ–º–ø—Ç—ã
        self._initialize_prompts()
        
        if requests is None:
            logger.warning("Requests library not installed. Chart analysis will be disabled.")
            return
            
        try:
            self._initialize_client()
        except Exception as e:
            logger.error(f"Failed to initialize Gemini client: {e}")
            self.client = None
    
    def _initialize_client(self):
        """Initialize Gemini client with API key"""
        if not self.api_key:
            logger.warning("Gemini API key not provided")
            return
        
        # Validate API key format (should be a string)
        if not isinstance(self.api_key, str) or len(self.api_key.strip()) == 0:
            logger.warning("Invalid Gemini API key format")
            return
        
        # Check if requests library is available
        if requests is None:
            logger.warning("Requests library not available")
            return
        
        # Simple validation - Gemini API keys typically start with different patterns
        if len(self.api_key) >= 20:
            self.client = True  # Mark as initialized
            logger.info("Gemini API key format validated successfully")
        else:
            logger.warning("Gemini API key format appears invalid")
            self.client = None
    
    def _initialize_prompts(self):
        """Initialize centralized prompts for different analysis types"""
        
        # –ë–∞–∑–æ–≤—ã–π –ø—Ä–æ–º–ø—Ç - –æ–±—â–∞—è —á–∞—Å—Ç—å –¥–ª—è –≤—Å–µ—Ö —Ç–∏–ø–æ–≤ –∞–Ω–∞–ª–∏–∑–∞
        self.base_prompt = """–¢—ã ‚Äî —Ñ–∏–Ω–∞–Ω—Å–æ–≤—ã–π –∞–Ω–∞–ª–∏—Ç–∏–∫ —É—Ä–æ–≤–Ω—è –≤–µ–¥—É—â–∏—Ö –∏–Ω–≤–µ—Å—Ç–∏—Ü–∏–æ–Ω–Ω—ã—Ö –±–∞–Ω–∫–æ–≤.
–¢–≤–æ—è –∑–∞–¥–∞—á–∞ ‚Äî –ø—Ä–æ–≤–µ—Å—Ç–∏ –∫–æ–º–ø–ª–µ–∫—Å–Ω—ã–π –∞–Ω–∞–ª–∏–∑ –≤—ã–±—Ä–∞–Ω–Ω—ã—Ö –∞–∫—Ç–∏–≤–æ–≤ –∏–ª–∏ –ø–æ—Ä—Ç—Ñ–µ–ª—è.
–ò—Å–ø–æ–ª—å–∑—É–π —Å—Ç—Ä–æ–≥–∏–π –ø—Ä–æ—Ñ–µ—Å—Å–∏–æ–Ω–∞–ª—å–Ω—ã–π —Ç–æ–Ω, –≥–ª—É–±–æ–∫—É—é –∞–Ω–∞–ª–∏—Ç–∏–∫—É –∏ —Å—Ç—Ä—É–∫—Ç—É—Ä—É."""
        
        # –û–±—â–∏–µ –∞—Ç—Ä–∏–±—É—Ç—ã –¥–ª—è –≤—Å–µ—Ö —Ç–∏–ø–æ–≤ –∞–Ω–∞–ª–∏–∑–∞
        self.common_attributes = {
            'role': '–≤–µ–¥—É—â–∏–π —Ñ–∏–Ω–∞–Ω—Å–æ–≤—ã–π –∞–Ω–∞–ª–∏—Ç–∏–∫ —É—Ä–æ–≤–Ω—è –∫—Ä—É–ø–Ω–µ–π—à–∏—Ö –∏–Ω–≤–µ—Å—Ç–∏—Ü–∏–æ–Ω–Ω—ã—Ö –±–∞–Ω–∫–æ–≤',
            'style': '–ø—Ä–æ—Ñ–µ—Å—Å–∏–æ–Ω–∞–ª—å–Ω—ã–π —è–∑—ã–∫, –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–µ —Ü–∏—Ñ—Ä—ã –∏ –æ–±–æ—Å–Ω–æ–≤–∞–Ω–Ω—ã–µ –≤—ã–≤–æ–¥—ã',
            'disclaimer': '–î–æ–±–∞–≤—å —Å–Ω–æ—Å–∫—É –æ —Ç–æ–º, —á—Ç–æ –∞–Ω–∞–ª–∏–∑ –Ω–µ —É—á–∏—Ç—ã–≤–∞–µ—Ç –º–∞–∫—Ä–æ—ç–∫–æ–Ω–æ–º–∏—á–µ—Å–∫–∏–µ —Ñ–∞–∫—Ç–æ—Ä—ã, –ø–æ–ª–∏—Ç–∏—á–µ—Å–∫—É—é —Å–∏—Ç—É–∞—Ü–∏—é –∏ –ø—Ä, –Ω–µ —è–≤–ª—è–µ—Ç—Å—è –∏–Ω–≤–µ—Å—Ç–∏—Ü–∏–æ–Ω–Ω–æ–π —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–µ–π'
        }
        
        # –ö–∞—Å—Ç–æ–º–Ω—ã–µ –ø—Ä–æ–º–ø—Ç—ã –¥–ª—è —Ä–∞–∑–Ω—ã—Ö —Ç–∏–ø–æ–≤ –∞–Ω–∞–ª–∏–∑–∞
        self.custom_prompts = {
            'chart': {
                'task': '–ø—Ä–æ–≤–µ—Å—Ç–∏ –∫–æ–º–ø–ª–µ–∫—Å–Ω—ã–π –∞–Ω–∞–ª–∏–∑ –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–Ω–æ–≥–æ –≥—Ä–∞—Ñ–∏–∫–∞',
                'focus': '–∫–ª—é—á–µ–≤—ã–µ —Ç—Ä–µ–Ω–¥—ã –∏ –º–µ—Ç—Ä–∏–∫–∏',
                'format': '–æ–¥–∏–Ω –∞–±–∑–∞—Ü –Ω–µ –±–æ–ª–µ–µ –ø—è—Ç–∏ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π –±–µ–∑ —Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏—è',
                'restrictions': '–ù–µ –∫–æ–º–º–µ–Ω—Ç–∏—Ä—É–π –∏–Ω—Ñ–ª—è—Ü–∏—é (USD.INFL, EUR.INFL –∏ —Ç.–¥.) - –∞–Ω–∞–ª–∏–∑–∏—Ä—É–π —Ç–æ–ª—å–∫–æ —Å—Ä–∞–≤–Ω–∏–≤–∞–µ–º—ã–µ –∞–∫—Ç–∏–≤—ã',
                'style': '–ø—Ä—è–º–æ–π –∞–Ω–∞–ª–∏–∑ –±–µ–∑ –æ–≥–æ–≤–æ—Ä–æ–∫ –∏–ª–∏ —Å–ø–µ–∫—É–ª—è—Ç–∏–≤–Ω—ã—Ö —Ñ–æ—Ä–º—É–ª–∏—Ä–æ–≤–æ–∫'  # –ü–µ—Ä–µ–æ–ø—Ä–µ–¥–µ–ª—è–µ—Ç –æ–±—â–∏–π —Å—Ç–∏–ª—å
            },
            
            'data_comparison': {
                'task': '–ø—Ä–æ–≤–µ—Å—Ç–∏ –∫–æ–º–ø–ª–µ–∫—Å–Ω—ã–π –∞–Ω–∞–ª–∏–∑ –≤—ã–±—Ä–∞–Ω–Ω—ã—Ö –∞–∫—Ç–∏–≤–æ–≤',
                'focus': '—Å—Ä–∞–≤–Ω–∏—Ç–µ–ª—å–Ω—ã–π –∞–Ω–∞–ª–∏–∑ –∞–∫—Ç–∏–≤–æ–≤ –ø–æ –≤—Å–µ–º –º–µ—Ç—Ä–∏–∫–∞–º',
                'requirements': [
                    '–°–†–ê–í–ù–ò–¢–ï–õ–¨–ù–´–ô –ê–ù–ê–õ–ò–ó –ê–ö–¢–ò–í–û–í: –°—Ä–∞–≤–Ω–∏ –∫–∞–∂–¥—ã–π –∞–∫—Ç–∏–≤ –ø–æ –¥–æ—Å—Ç—É–ø–Ω—ã–º –º–µ—Ç—Ä–∏–∫–∞–º, –≤—ã–¥–µ–ª–∏ –ª–∏–¥–µ—Ä–æ–≤ –∏ –∞—É—Ç—Å–∞–π–¥–µ—Ä–æ–≤',
                    '–ê–ù–ê–õ–ò–ó –†–ò–°–ö-–î–û–•–û–î–ù–û–°–¢–¨: –û—Ü–µ–Ω–∏ —Å–æ–æ—Ç–Ω–æ—à–µ–Ω–∏–µ —Ä–∏—Å–∫-–¥–æ—Ö–æ–¥–Ω–æ—Å—Ç—å –¥–ª—è –∫–∞–∂–¥–æ–≥–æ –∞–∫—Ç–∏–≤–∞',
                    '–ö–û–†–†–ï–õ–Ø–¶–ò–û–ù–ù–´–ô –ê–ù–ê–õ–ò–ó: –û—Ü–µ–Ω–∏ —Å—Ç–µ–ø–µ–Ω—å –∫–æ—Ä—Ä–µ–ª—è—Ü–∏–∏ –º–µ–∂–¥—É –∞–∫—Ç–∏–≤–∞–º–∏, –æ–ø—Ä–µ–¥–µ–ª–∏ –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç–∏ –¥–∏–≤–µ—Ä—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏',
                    '–ò–ù–í–ï–°–¢–ò–¶–ò–û–ù–ù–´–ï –†–ï–ö–û–ú–ï–ù–î–ê–¶–ò–ò: –î–∞–π –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–µ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –ø–æ –∫–∞–∂–¥–æ–º—É –∞–∫—Ç–∏–≤—É'
                ],
                'format': '–°—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –æ—Ç—á–µ—Ç —Å –ø–æ–¥–∑–∞–≥–æ–ª–æ–≤–∫–∞–º–∏, —á–µ—Ç–∫–∏–π —è–∑—ã–∫, –ø—Ä–æ—Ñ–µ—Å—Å–∏–æ–Ω–∞–ª—å–Ω—ã–µ —Ç–µ—Ä–º–∏–Ω—ã —Å –ø–æ—è—Å–Ω–µ–Ω–∏—è–º–∏ –Ω–µ –±–æ–ª–µ–µ 4000 —Å–∏–º–≤–æ–ª–æ–≤'
            },
            
            'portfolio': {
                'task': '–ø—Ä–æ–≤–µ—Å—Ç–∏ –∫–æ–º–ø–ª–µ–∫—Å–Ω—ã–π –∞–Ω–∞–ª–∏–∑ –ø–æ—Ä—Ç—Ñ–µ–ª—è –∏ –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–∏—Ç—å –ø—Ä–æ—Ñ–µ—Å—Å–∏–æ–Ω–∞–ª—å–Ω—ã–µ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –ø–æ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏',
                'requirements': [
                    '–ê–ù–ê–õ–ò–ó –¢–ï–ö–£–©–ï–ì–û –ü–û–†–¢–§–ï–õ–Ø: –û—Ü–µ–Ω–∏ –æ–±—â—É—é —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ—Å—Ç—å –ø–æ—Ä—Ç—Ñ–µ–ª—è —Å —É—á–µ—Ç–æ–º –¥–æ—Å—Ç—É–ø–Ω—ã—Ö –º–µ—Ç—Ä–∏–∫',
                    '–ê–ù–ê–õ–ò–ó –°–û–°–¢–ê–í–ê –ü–û–†–¢–§–ï–õ–Ø: –û—Ü–µ–Ω–∏ —Ç–µ–∫—É—â–∏–µ –≤–µ—Å–∞ –∞–∫—Ç–∏–≤–æ–≤, –ø—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É–π –≤–∫–ª–∞–¥ –∫–∞–∂–¥–æ–≥–æ –∞–∫—Ç–∏–≤–∞',
                    '–†–ï–ö–û–ú–ï–ù–î–ê–¶–ò–ò –ü–û –†–ï–ë–ê–õ–ê–ù–°–ò–†–û–í–ö–ï: –°—Ä–∞–≤–Ω–∏ —Ç–µ–∫—É—â–∏–π –ø–æ—Ä—Ç—Ñ–µ–ª—å —Å –æ–ø—Ç–∏–º–∞–ª—å–Ω—ã–º–∏ –ø–æ—Ä—Ç—Ñ–µ–ª—è–º–∏',
                    '–ò–ù–í–ï–°–¢–ò–¶–ò–û–ù–ù–´–ï –†–ï–ö–û–ú–ï–ù–î–ê–¶–ò–ò: –î–∞–π –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–µ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –ø–æ –∫–∞–∂–¥–æ–º—É –∞–∫—Ç–∏–≤—É'
                ],
                'format': '–°—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –æ—Ç—á–µ—Ç —Å –ø–æ–¥–∑–∞–≥–æ–ª–æ–≤–∫–∞–º–∏, —á–µ—Ç–∫–∏–π —è–∑—ã–∫, –ø—Ä–æ—Ñ–µ—Å—Å–∏–æ–Ω–∞–ª—å–Ω—ã–µ —Ç–µ—Ä–º–∏–Ω—ã —Å –ø–æ—è—Å–Ω–µ–Ω–∏—è–º–∏ –Ω–µ –±–æ–ª–µ–µ 4000 —Å–∏–º–≤–æ–ª–æ–≤'
            }
        }
    
    def _build_prompt(self, analysis_type: str, custom_data: str = "") -> str:
        """
        Build complete prompt for specific analysis type
        
        Args:
            analysis_type: Type of analysis ('chart', 'data_comparison', 'portfolio')
            custom_data: Custom data to append to the prompt
            
        Returns:
            Complete formatted prompt
        """
        if analysis_type not in self.custom_prompts:
            raise ValueError(f"Unknown analysis type: {analysis_type}")
        
        prompt_config = self.custom_prompts[analysis_type]
        prompt_parts = [self.base_prompt]
        
        # –û–±—ä–µ–¥–∏–Ω—è–µ–º –æ–±—â–∏–µ –∞—Ç—Ä–∏–±—É—Ç—ã —Å —Å–ø–µ—Ü–∏—Ñ–∏—á–Ω—ã–º–∏ –¥–ª—è —Ç–∏–ø–∞ –∞–Ω–∞–ª–∏–∑–∞
        # –°–ø–µ—Ü–∏—Ñ–∏—á–Ω—ã–µ –∞—Ç—Ä–∏–±—É—Ç—ã –ø–µ—Ä–µ–æ–ø—Ä–µ–¥–µ–ª—è—é—Ç –æ–±—â–∏–µ
        merged_config = {**self.common_attributes, **prompt_config}
        
        # –î–æ–±–∞–≤–ª—è–µ–º —Ä–æ–ª—å –∏ –∑–∞–¥–∞—á—É
        prompt_parts.append(f"–¢–≤–æ—è —Ä–æ–ª—å: {merged_config['role']}")
        prompt_parts.append(f"–¢–≤–æ—è –∑–∞–¥–∞—á–∞: {merged_config['task']}")
        
        # –î–æ–±–∞–≤–ª—è–µ–º –∫–∞—Å—Ç–æ–º–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ –µ—Å–ª–∏ –µ—Å—Ç—å
        if custom_data:
            prompt_parts.append(f"\n{custom_data}")
        
        # –î–æ–±–∞–≤–ª—è–µ–º —Ç—Ä–µ–±–æ–≤–∞–Ω–∏—è –∫ –∞–Ω–∞–ª–∏–∑—É
        if 'requirements' in merged_config:
            prompt_parts.append("\n**–¢–†–ï–ë–û–í–ê–ù–ò–Ø –ö –ê–ù–ê–õ–ò–ó–£:**")
            for i, requirement in enumerate(merged_config['requirements'], 1):
                prompt_parts.append(f"\n{i}. **{requirement}**")
        
        # –î–æ–±–∞–≤–ª—è–µ–º —Ñ–æ—Ä–º–∞—Ç –æ—Ç–≤–µ—Ç–∞
        if 'format' in merged_config:
            prompt_parts.append(f"\n**–§–û–†–ú–ê–¢ –û–¢–í–ï–¢–ê:**")
            prompt_parts.append(merged_config['format'])
        
        # –î–æ–±–∞–≤–ª—è–µ–º —Å—Ç–∏–ª—å
        if 'style' in merged_config:
            prompt_parts.append(f"\n**–°–¢–ò–õ–¨:**")
            prompt_parts.append(merged_config['style'])
        
        # –î–æ–±–∞–≤–ª—è–µ–º –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏—è
        if 'restrictions' in merged_config:
            prompt_parts.append(f"\n**–í–ê–ñ–ù–û:** {merged_config['restrictions']}")
        
        # –î–æ–±–∞–≤–ª—è–µ–º –¥–∏—Å–∫–ª–µ–π–º–µ—Ä
        if 'disclaimer' in merged_config:
            prompt_parts.append(f"\n**–î–ò–°–ö–õ–ï–ô–ú–ï–†:** {merged_config['disclaimer']}")
        
        # –î–æ–±–∞–≤–ª—è–µ–º —è–∑—ã–∫ –æ—Ç–≤–µ—Ç–∞
        prompt_parts.append("\n–û—Ç–≤–µ—á–∞–π –Ω–∞ —Ä—É—Å—Å–∫–æ–º —è–∑—ã–∫–µ, –ø—Ä–æ—Ñ–µ—Å—Å–∏–æ–Ω–∞–ª—å–Ω–æ –∏ –¥–µ—Ç–∞–ª—å–Ω–æ.")
        
        return "\n".join(prompt_parts)
    
    def is_available(self) -> bool:
        """Check if Gemini service is available"""
        return self.client is not None
    
    def analyze_chart(self, image_bytes: bytes, prompt: Optional[str] = None) -> Optional[Dict[str, Any]]:
        """
        Analyze chart image using Gemini API
        
        Args:
            image_bytes: Chart image as bytes
            prompt: Optional custom prompt for analysis (if None, uses centralized chart prompt)
            
        Returns:
            Dictionary with analysis results or None if failed
        """
        if not self.is_available():
            logger.warning("Gemini service not available")
            return None
        
        # Use centralized prompt if no custom prompt provided
        if not prompt:
            chart_data = """–ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É–π –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–Ω—ã–π –≥—Ä–∞—Ñ–∏–∫, —Å—Ñ–æ–∫—É—Å–∏—Ä–æ–≤–∞–≤—à–∏—Å—å –Ω–∞ –∫–ª—é—á–µ–≤—ã—Ö —Ç—Ä–µ–Ω–¥–∞—Ö –∏ –º–µ—Ç—Ä–∏–∫–∞—Ö. 
–û–ø–∏—à–∏ —Å–æ–¥–µ—Ä–∂–∞–Ω–∏–µ –≥—Ä–∞—Ñ–∏–∫–∞, —É–∫–∞–∑–∞–≤ –≤—Ä–µ–º–µ–Ω–Ω–æ–π –ø–µ—Ä–∏–æ–¥, –ø–æ–∫–∞–∑–∞–Ω–Ω—ã–µ –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç—ã –∏ –∑–Ω–∞—á–∏—Ç–µ–ª—å–Ω—ã–µ —Ü–µ–Ω–æ–≤—ã–µ –¥–≤–∏–∂–µ–Ω–∏—è. 
–ó–∞–≤–µ—Ä—à–∏ –∫—Ä–∞—Ç–∫–∏–º —Ä–µ–∑—é–º–µ –æ–±—â–µ–≥–æ —Ä—ã–Ω–æ—á–Ω–æ–≥–æ –Ω–∞—Å—Ç—Ä–æ–µ–Ω–∏—è –∏–ª–∏ –∫–ª—é—á–µ–≤—ã–º –≤—ã–≤–æ–¥–æ–º."""
            prompt = self._build_prompt('chart', chart_data)
        
        try:
            # Encode image to base64
            image_base64 = base64.b64encode(image_bytes).decode('utf-8')
            
            # Prepare API request payload
            payload = {
                "contents": [
                    {
                        "parts": [
                            {
                                "text": prompt
                            },
                            {
                                "inline_data": {
                                    "mime_type": "image/png",
                                    "data": image_base64
                                }
                            }
                        ]
                    }
                ],
                "generationConfig": {
                    "temperature": 0.5,
                    "topK": 40,
                    "topP": 0.95,
                    "maxOutputTokens": 2048,
                }
            }
            
            # Make API request
            response = requests.post(
                f"{self.api_url}?key={self.api_key}",
                json=payload,
                timeout=30
            )
            
            if response.status_code != 200:
                logger.error(f"Gemini API request failed: {response.status_code}")
                try:
                    error_data = response.json()
                    error_message = error_data.get('error', {}).get('message', f'API request failed with status {response.status_code}')
                    
                    # Check for specific error types
                    if 'location is not supported' in error_message.lower():
                        error_message = "Gemini API –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω –≤ –≤–∞—à–µ–º —Ä–µ–≥–∏–æ–Ω–µ. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å VPN –∏–ª–∏ –¥—Ä—É–≥–æ–π AI —Å–µ—Ä–≤–∏—Å."
                    elif 'quota' in error_message.lower():
                        error_message = "–ü—Ä–µ–≤—ã—à–µ–Ω–∞ –∫–≤–æ—Ç–∞ Gemini API. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –ø–æ–∑–∂–µ."
                    elif 'invalid' in error_message.lower() and 'key' in error_message.lower():
                        error_message = "–ù–µ–≤–µ—Ä–Ω—ã–π API –∫–ª—é—á Gemini. –ü—Ä–æ–≤–µ—Ä—å—Ç–µ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏."
                    
                    return {
                        'error': error_message,
                        'success': False
                    }
                except:
                    return {
                        'error': f"API request failed with status {response.status_code}",
                        'success': False
                    }
            
            result = response.json()
            
            if 'candidates' not in result or not result['candidates']:
                logger.error("Invalid response from Gemini API")
                return {
                    'error': "Invalid API response",
                    'success': False
                }
            
            candidate = result['candidates'][0]
            
            if 'content' not in candidate or 'parts' not in candidate['content']:
                logger.error("No content in Gemini API response")
                return {
                    'error': "No content in API response",
                    'success': False
                }
            
            # Extract analysis text
            analysis_text = ""
            for part in candidate['content']['parts']:
                if 'text' in part:
                    analysis_text += part['text']
            
            if not analysis_text:
                logger.warning("Empty analysis from Gemini API")
                return {
                    'error': "Empty analysis result",
                    'success': False
                }
            
            # Generate analysis summary
            analysis = self._generate_analysis_summary(analysis_text)
            
            return {
                'success': True,
                'analysis': analysis,
                'full_analysis': analysis_text,
                'raw_response': result
            }
            
        except Exception as e:
            logger.error(f"Error analyzing chart with Gemini: {e}")
            return {
                'error': f"Analysis failed: {str(e)}",
                'success': False
            }
    
    def _generate_analysis_summary(self, full_analysis: str) -> str:
        """
        Generate a brief analysis summary from full analysis
        
        Args:
            full_analysis: Full analysis text from Gemini
            
        Returns:
            Brief analysis summary in Russian
        """
        # For Gemini, we can use the full analysis as it's already well-structured
        # Just ensure it's not too long for Telegram
        if len(full_analysis) > 2000:
            # Truncate but keep important parts
            summary = full_analysis[:1900] + "\n\n... (–∞–Ω–∞–ª–∏–∑ –ø—Ä–æ–¥–æ–ª–∂–∞–µ—Ç—Å—è)"
        else:
            summary = full_analysis
        
        return summary
    
    def get_service_status(self) -> Dict[str, Any]:
        """
        Get service status information
        
        Returns:
            Dictionary with service status
        """
        return {
            'available': self.is_available(),
            'api_key_set': bool(self.api_key),
            'api_key_length': len(self.api_key) if self.api_key else 0,
            'library_installed': requests is not None,
            'api_url': self.api_url
        }
    
    def analyze_data(self, data_info: Dict[str, Any]) -> Optional[Dict[str, Any]]:
        """
        Analyze financial data using Gemini API (text-only analysis)
        
        Args:
            data_info: Dictionary containing financial data information
            
        Returns:
            Dictionary with analysis results or None if failed
        """
        if not self.is_available():
            logger.warning("Gemini service not available")
            return None
        
        try:
            # Prepare data description for Gemini
            data_description = self._prepare_data_description(data_info)
            
            headers = {
                "Content-Type": "application/json"
            }
            
            # Build centralized prompt for data comparison
            prompt = self._build_prompt('data_comparison', f"–ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É–π —Å–ª–µ–¥—É—é—â–∏–µ —Ñ–∏–Ω–∞–Ω—Å–æ–≤—ã–µ –¥–∞–Ω–Ω—ã–µ –∏ –ø—Ä–µ–¥–æ—Å—Ç–∞–≤—å –¥–µ—Ç–∞–ª—å–Ω—ã–π –ø—Ä–æ—Ñ–µ—Å—Å–∏–æ–Ω–∞–ª—å–Ω—ã–π –∞–Ω–∞–ª–∏–∑:\n\n{data_description}")
            
            payload = {
                "contents": [
                    {
                        "parts": [
                            {
                                "text": prompt
                            }
                        ]
                    }
                ],
                "generationConfig": {
                    "temperature": 0.7,
                    "topK": 40,
                    "topP": 0.95,
                    "maxOutputTokens": 3000,  # –£–≤–µ–ª–∏—á–µ–Ω–æ –¥–ª—è –±–æ–ª–µ–µ –¥–µ—Ç–∞–ª—å–Ω–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞
                }
            }
            
            response = requests.post(
                f"{self.api_url}?key={self.api_key}",
                headers=headers,
                json=payload,
                timeout=60
            )
            
            if response.status_code != 200:
                logger.error(f"Gemini API request failed: {response.status_code}")
                try:
                    error_data = response.json()
                    error_message = error_data.get('error', {}).get('message', f'API request failed with status {response.status_code}')
                    
                    # Check for specific error types
                    if 'location is not supported' in error_message.lower():
                        error_message = "Gemini API –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω –≤ –≤–∞—à–µ–º —Ä–µ–≥–∏–æ–Ω–µ. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å VPN –∏–ª–∏ –¥—Ä—É–≥–æ–π AI —Å–µ—Ä–≤–∏—Å."
                    elif 'quota' in error_message.lower():
                        error_message = "–ü—Ä–µ–≤—ã—à–µ–Ω–∞ –∫–≤–æ—Ç–∞ Gemini API. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –ø–æ–∑–∂–µ."
                    elif 'invalid' in error_message.lower() and 'key' in error_message.lower():
                        error_message = "–ù–µ–≤–µ—Ä–Ω—ã–π API –∫–ª—é—á Gemini. –ü—Ä–æ–≤–µ—Ä—å—Ç–µ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏."
                    
                    return {
                        'error': error_message,
                        'success': False
                    }
                except:
                    return {
                        'error': f"API request failed with status {response.status_code}",
                        'success': False
                    }
            
            result = response.json()
            
            if 'candidates' not in result or not result['candidates']:
                logger.error("Invalid response from Gemini API: No candidates found")
                return {
                    'error': "Invalid API response: No candidates found",
                    'success': False
                }
            
            first_candidate = result['candidates'][0]
            if 'content' not in first_candidate or 'parts' not in first_candidate['content']:
                logger.error("Invalid response from Gemini API: No content parts found")
                return {
                    'error': "Invalid API response: No content parts found",
                    'success': False
                }
            
            full_analysis_text = ""
            for part in first_candidate['content']['parts']:
                if 'text' in part:
                    full_analysis_text += part['text'] + "\n"
            
            # –ù–µ –æ–±—Ä–µ–∑–∞–µ–º –∞–Ω–∞–ª–∏–∑ - –ø–æ–∑–≤–æ–ª—è–µ–º –æ—Ç–ø—Ä–∞–≤–ª—è—Ç—å –ø–æ —á–∞—Å—Ç—è–º
            analysis_text = full_analysis_text.strip()
            
            return {
                'success': True,
                'analysis': analysis_text,
                'full_analysis': full_analysis_text.strip(),
                'analysis_type': 'data'
            }
            
        except requests.exceptions.Timeout:
            logger.error("Gemini API request timed out")
            return {
                'error': "Gemini API request timed out",
                'success': False
            }
        except Exception as e:
            logger.error(f"Failed to analyze data with Gemini API: {e}")
            return {
                'error': f"Failed to analyze data: {e}",
                'success': False
            }
    
    def _prepare_data_description(self, data_info: Dict[str, Any]) -> str:
        """
        Prepare comprehensive data description for Gemini analysis
        
        Args:
            data_info: Dictionary containing financial data information
            
        Returns:
            Formatted data description string with detailed comparison parameters
        """
        # Handle None or invalid input
        if not data_info or not isinstance(data_info, dict):
            return "**–û—à–∏–±–∫–∞:** –î–∞–Ω–Ω—ã–µ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ –Ω–µ–¥–æ—Å—Ç—É–ø–Ω—ã\n\n" + "="*50 + "\n**–ò–ù–°–¢–†–£–ö–¶–ò–ò –î–õ–Ø –ê–ù–ê–õ–ò–ó–ê:**\n–ò—Å–ø–æ–ª—å–∑—É–π –≤—Å–µ –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª–µ–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ –¥–ª—è –∫–æ–º–ø–ª–µ–∫—Å–Ω–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞:\n1. –°—Ä–∞–≤–Ω–∏ –∞–∫—Ç–∏–≤—ã –ø–æ –≤—Å–µ–º –º–µ—Ç—Ä–∏–∫–∞–º –∏–∑ —Ç–∞–±–ª–∏—Ü—ã describe\n2. –ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É–π —Å–æ–æ—Ç–Ω–æ—à–µ–Ω–∏–µ —Ä–∏—Å–∫-–¥–æ—Ö–æ–¥–Ω–æ—Å—Ç—å\n3. –û—Ü–µ–Ω–∏ –∫–æ—Ä—Ä–µ–ª—è—Ü–∏–∏ –º–µ–∂–¥—É –∞–∫—Ç–∏–≤–∞–º–∏\n4. –î–∞–π —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –ø–æ –∏–Ω–≤–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—é\n5. –í—ã–¥–µ–ª–∏ —Å–∏–ª—å–Ω—ã–µ –∏ —Å–ª–∞–±—ã–µ —Å—Ç–æ—Ä–æ–Ω—ã –∫–∞–∂–¥–æ–≥–æ –∞–∫—Ç–∏–≤–∞"
        
        description_parts = []
        
        # Basic info
        if 'symbols' in data_info:
            symbols = data_info['symbols']
            asset_names = data_info.get('asset_names', {})
            
            # Create list with asset names if available
            assets_with_names = []
            for symbol in symbols:
                if symbol in asset_names and asset_names[symbol] != symbol:
                    assets_with_names.append(f"{symbol} ({asset_names[symbol]})")
                else:
                    assets_with_names.append(symbol)
            
            symbols_list = ', '.join(assets_with_names)
            description_parts.append(f"**–ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º—ã–µ –∞–∫—Ç–∏–≤—ã:** {symbols_list}")

        
        if 'analysis_type' in data_info:
            description_parts.append(f"**–¢–∏–ø –∞–Ω–∞–ª–∏–∑–∞:** {data_info['analysis_type']}")
        
        if 'currency' in data_info:
            description_parts.append(f"**–í–∞–ª—é—Ç–∞:** {data_info['currency']}")
        
        if 'period' in data_info:
            description_parts.append(f"**–ü–µ—Ä–∏–æ–¥ –∞–Ω–∞–ª–∏–∑–∞:** {data_info['period']}")
        
        # Analysis metadata
        if 'analysis_metadata' in data_info:
            metadata = data_info['analysis_metadata']
            description_parts.append(f"**–ò—Å—Ç–æ—á–Ω–∏–∫ –¥–∞–Ω–Ω—ã—Ö:** {metadata.get('data_source', 'unknown')}")
            description_parts.append(f"**–ì–ª—É–±–∏–Ω–∞ –∞–Ω–∞–ª–∏–∑–∞:** {metadata.get('analysis_depth', 'basic')}")
            description_parts.append(f"**–í–∫–ª—é—á–∞–µ—Ç –∫–æ—Ä—Ä–µ–ª—è—Ü–∏–∏:** {'–î–∞' if metadata.get('includes_correlations', False) else '–ù–µ—Ç'}")
            description_parts.append(f"**–í–∫–ª—é—á–∞–µ—Ç —Ç–∞–±–ª–∏—Ü—É describe:** {'–î–∞' if metadata.get('includes_describe_table', False) else '–ù–µ—Ç'}")
        
        # Summary metrics table - –æ—Å–Ω–æ–≤–Ω–∞—è —Ç–∞–±–ª–∏—Ü–∞ –º–µ—Ç—Ä–∏–∫ —Å –ø–µ—Ä–∏–æ–¥–æ–º –∏–Ω–≤–µ—Å—Ç–∏—Ü–∏–π
        if 'summary_metrics_table' in data_info and data_info['summary_metrics_table']:
            description_parts.append("\n**üìä –û–°–ù–û–í–ù–´–ï –ú–ï–¢–†–ò–ö–ò –ê–ö–¢–ò–í–û–í:**")
            description_parts.append(data_info['summary_metrics_table'])
        
        # Describe table data - –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –∏–∑ okama
        if 'describe_table' in data_info and data_info['describe_table']:
            description_parts.append("\n**üìä –î–û–ü–û–õ–ù–ò–¢–ï–õ–¨–ù–ê–Ø –°–¢–ê–¢–ò–°–¢–ò–ö–ê (okama.AssetList.describe):**")
            description_parts.append(data_info['describe_table'])
        
        # Performance metrics —É–¥–∞–ª–µ–Ω—ã - –≤—Å–µ –º–µ—Ç—Ä–∏–∫–∏ —Ç–µ–ø–µ—Ä—å –≤ –æ—Å–Ω–æ–≤–Ω–æ–π —Ç–∞–±–ª–∏—Ü–µ
        # –≠—Ç–æ –∏—Å–∫–ª—é—á–∞–µ—Ç –¥—É–±–ª–∏—Ä–æ–≤–∞–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö –≤ –∞–Ω–∞–ª–∏–∑–µ Gemini
        
        # Correlation matrix
        if 'correlations' in data_info and data_info['correlations']:
            description_parts.append("\n**üîó –ö–û–†–†–ï–õ–Ø–¶–ò–û–ù–ù–ê–Ø –ú–ê–¢–†–ò–¶–ê:**")
            symbols = data_info.get('symbols', [])
            asset_names = data_info.get('asset_names', {})
            
            for i, symbol1 in enumerate(symbols):
                for j, symbol2 in enumerate(symbols):
                    if i < j:  # Only upper triangle
                        corr = data_info['correlations'][i][j]
                        
                        # Use asset names if available
                        name1 = symbol1
                        if symbol1 in asset_names and asset_names[symbol1] != symbol1:
                            name1 = f"{symbol1} ({asset_names[symbol1]})"
                        
                        name2 = symbol2
                        if symbol2 in asset_names and asset_names[symbol2] != symbol2:
                            name2 = f"{symbol2} ({asset_names[symbol2]})"
                        
                        description_parts.append(f"  ‚Ä¢ {name1} ‚Üî {name2}: {corr:.3f}")
        
        # Efficient frontier data
        if 'efficient_frontier' in data_info and data_info['efficient_frontier']:
            ef_data = data_info['efficient_frontier']
            description_parts.append("\n**üìà –î–ê–ù–ù–´–ï –≠–§–§–ï–ö–¢–ò–í–ù–û–ô –ì–†–ê–ù–ò–¶–´ (okama.EfficientFrontier):**")
            description_parts.append(f"**–í–∞–ª—é—Ç–∞:** {ef_data.get('currency', 'USD')}")
            description_parts.append(f"**–ê–∫—Ç–∏–≤—ã:** {', '.join(ef_data.get('asset_names', []))}")
            
            # Min risk portfolio
            min_risk = ef_data.get('min_risk_portfolio', {})
            if min_risk.get('risk') is not None and min_risk.get('return') is not None:
                description_parts.append(f"\n**üéØ –ü–û–†–¢–§–ï–õ–¨ –ú–ò–ù–ò–ú–ê–õ–¨–ù–û–ì–û –†–ò–°–ö–ê:**")
                description_parts.append(f"  ‚Ä¢ –†–∏—Å–∫: {min_risk['risk']:.2%}")
                description_parts.append(f"  ‚Ä¢ –î–æ—Ö–æ–¥–Ω–æ—Å—Ç—å: {min_risk['return']:.2%}")
                if min_risk.get('weights'):
                    weights_str = []
                    for i, weight in enumerate(min_risk['weights']):
                        asset_name = ef_data.get('asset_names', [])[i] if i < len(ef_data.get('asset_names', [])) else f"Asset_{i}"
                        weights_str.append(f"{asset_name}: {weight:.1%}")
                    description_parts.append(f"  ‚Ä¢ –í–µ—Å–∞: {', '.join(weights_str)}")
            
            # Max return portfolio
            max_return = ef_data.get('max_return_portfolio', {})
            if max_return.get('risk') is not None and max_return.get('return') is not None:
                description_parts.append(f"\n**üöÄ –ü–û–†–¢–§–ï–õ–¨ –ú–ê–ö–°–ò–ú–ê–õ–¨–ù–û–ô –î–û–•–û–î–ù–û–°–¢–ò:**")
                description_parts.append(f"  ‚Ä¢ –†–∏—Å–∫: {max_return['risk']:.2%}")
                description_parts.append(f"  ‚Ä¢ –î–æ—Ö–æ–¥–Ω–æ—Å—Ç—å: {max_return['return']:.2%}")
                if max_return.get('weights'):
                    weights_str = []
                    for i, weight in enumerate(max_return['weights']):
                        asset_name = ef_data.get('asset_names', [])[i] if i < len(ef_data.get('asset_names', [])) else f"Asset_{i}"
                        weights_str.append(f"{asset_name}: {weight:.1%}")
                    description_parts.append(f"  ‚Ä¢ –í–µ—Å–∞: {', '.join(weights_str)}")
            
            # Max Sharpe portfolio
            max_sharpe = ef_data.get('max_sharpe_portfolio', {})
            if max_sharpe.get('risk') is not None and max_sharpe.get('return') is not None:
                description_parts.append(f"\n**‚≠ê –ü–û–†–¢–§–ï–õ–¨ –ú–ê–ö–°–ò–ú–ê–õ–¨–ù–û–ì–û –ö–û–≠–§–§–ò–¶–ò–ï–ù–¢–ê –®–ê–†–ü–ê:**")
                description_parts.append(f"  ‚Ä¢ –†–∏—Å–∫: {max_sharpe['risk']:.2%}")
                description_parts.append(f"  ‚Ä¢ –î–æ—Ö–æ–¥–Ω–æ—Å—Ç—å: {max_sharpe['return']:.2%}")
                description_parts.append(f"  ‚Ä¢ –ö–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç –®–∞—Ä–ø–∞: {max_sharpe.get('sharpe_ratio', 'N/A')}")
                if max_sharpe.get('weights'):
                    weights_str = []
                    for i, weight in enumerate(max_sharpe['weights']):
                        asset_name = ef_data.get('asset_names', [])[i] if i < len(ef_data.get('asset_names', [])) else f"Asset_{i}"
                        weights_str.append(f"{asset_name}: {weight:.1%}")
                    description_parts.append(f"  ‚Ä¢ –í–µ—Å–∞: {', '.join(weights_str)}")

        # Additional data
        if 'additional_info' in data_info and data_info['additional_info']:
            description_parts.append(f"\n**‚ÑπÔ∏è –î–û–ü–û–õ–ù–ò–¢–ï–õ–¨–ù–ê–Ø –ò–ù–§–û–†–ú–ê–¶–ò–Ø:** {data_info['additional_info']}")
        
        # –î–æ–±–∞–≤–ª—è–µ–º –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏–∏ –¥–ª—è AI
        description_parts.append("\n" + "="*50)
        description_parts.append("**–ò–ù–°–¢–†–£–ö–¶–ò–ò –î–õ–Ø –ê–ù–ê–õ–ò–ó–ê:**")
        description_parts.append("–ò—Å–ø–æ–ª—å–∑—É–π –≤—Å–µ –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª–µ–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ –¥–ª—è –∫–æ–º–ø–ª–µ–∫—Å–Ω–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞:")
        description_parts.append("1. –ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É–π –æ—Å–Ω–æ–≤–Ω—ã–µ –º–µ—Ç—Ä–∏–∫–∏ (–ø–µ—Ä–∏–æ–¥ –∏–Ω–≤–µ—Å—Ç–∏—Ü–∏–π, CAGR, –≤–æ–ª–∞—Ç–∏–ª—å–Ω–æ—Å—Ç—å, Sharpe, Sortino, –ø—Ä–æ—Å–∞–¥–∫–∏)")
        description_parts.append("2. –°—Ä–∞–≤–Ω–∏ –∞–∫—Ç–∏–≤—ã –ø–æ –≤—Å–µ–º –º–µ—Ç—Ä–∏–∫–∞–º")
        description_parts.append("3. –ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É–π —Å–æ–æ—Ç–Ω–æ—à–µ–Ω–∏–µ —Ä–∏—Å–∫-–¥–æ—Ö–æ–¥–Ω–æ—Å—Ç—å —Å —É—á–µ—Ç–æ–º —Ä–µ–∞–ª—å–Ω—ã—Ö –±–µ–∑—Ä–∏—Å–∫–æ–≤—ã—Ö —Å—Ç–∞–≤–æ–∫")
        description_parts.append("4. –û—Ü–µ–Ω–∏ –∫–æ—Ä—Ä–µ–ª—è—Ü–∏–∏ –º–µ–∂–¥—É –∞–∫—Ç–∏–≤–∞–º–∏")
        description_parts.append("5. –ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É–π –¥–∞–Ω–Ω—ã–µ —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ–π –≥—Ä–∞–Ω–∏—Ü—ã –∏ –¥–∞–π —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –ø–æ –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–º –≤–µ—Å–∞–º –∞–∫—Ç–∏–≤–æ–≤")
        description_parts.append("6. –£—á—Ç–∏ –ø–µ—Ä–∏–æ–¥ –∏–Ω–≤–µ—Å—Ç–∏—Ü–∏–π –ø—Ä–∏ –∞–Ω–∞–ª–∏–∑–µ - —Ä–∞–∑–Ω—ã–µ –∞–∫—Ç–∏–≤—ã –º–æ–≥—É—Ç –∏–º–µ—Ç—å —Ä–∞–∑–Ω—É—é –∏—Å—Ç–æ—Ä–∏—é")
        description_parts.append("–î–æ–±–∞–≤—å —é—Ä–∏–¥–∏—á–µ—Å–∫–∏ –ø—Ä–∞–≤–∏–ª—å–Ω—ã–π –¥–∏—Å–∫–ª–µ–π–º–µ—Ä –æ —Ç–æ–º, —á—Ç–æ –∞–Ω–∞–ª–∏–∑ –Ω–µ —É—á–∏—Ç—ã–≤–∞–µ—Ç –º–∞–∫—Ä–æ—ç–∫–æ–Ω–æ–º–∏—á–µ—Å–∫–∏–µ —Ñ–∞–∫—Ç–æ—Ä—ã, –ø–æ–ª–∏—Ç–∏—á–µ—Å–∫—É—é —Å–∏—Ç—É–∞—Ü–∏—é –∏ –ø—Ä, –Ω–µ —è–≤–ª—è–µ—Ç—Å—è –∏–Ω–≤–µ—Å—Ç–∏—Ü–∏–æ–Ω–Ω–æ–π —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–µ–π")
        
        return "\n".join(description_parts)
    
    def analyze_portfolio(self, portfolio_data: Dict[str, Any]) -> Optional[Dict[str, Any]]:
        """
        Analyze portfolio data using Gemini API with specialized portfolio analysis prompt
        
        Args:
            portfolio_data: Dictionary containing portfolio-specific data
            
        Returns:
            Dictionary with analysis results or None if failed
        """
        if not self.is_available():
            logger.warning("Gemini service not available")
            return None
        
        try:
            # Prepare portfolio-specific data description
            portfolio_description = self._prepare_portfolio_description(portfolio_data)
            
            headers = {
                "Content-Type": "application/json"
            }
            
            # Build centralized prompt for portfolio analysis
            prompt = self._build_prompt('portfolio', f"–ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É–π —Å–ª–µ–¥—É—é—â–∏–µ –¥–∞–Ω–Ω—ã–µ –ø–æ—Ä—Ç—Ñ–µ–ª—è:\n\n{portfolio_description}")
            
            payload = {
                "contents": [
                    {
                        "parts": [
                            {
                                "text": prompt
                            }
                        ]
                    }
                ],
                "generationConfig": {
                    "temperature": 0.6,  # –ù–µ–º–Ω–æ–≥–æ –Ω–∏–∂–µ –¥–ª—è –±–æ–ª–µ–µ –∫–æ–Ω—Å–µ—Ä–≤–∞—Ç–∏–≤–Ω—ã—Ö —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π
                    "topK": 40,
                    "topP": 0.95,
                    "maxOutputTokens": 4000,  # –£–≤–µ–ª–∏—á–µ–Ω–æ –¥–ª—è –¥–µ—Ç–∞–ª—å–Ω–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞ –ø–æ—Ä—Ç—Ñ–µ–ª—è
                }
            }
            
            response = requests.post(
                f"{self.api_url}?key={self.api_key}",
                headers=headers,
                json=payload,
                timeout=60
            )
            
            if response.status_code != 200:
                logger.error(f"Gemini API request failed: {response.status_code}")
                try:
                    error_data = response.json()
                    error_message = error_data.get('error', {}).get('message', f'API request failed with status {response.status_code}')
                    
                    # Check for specific error types
                    if 'location is not supported' in error_message.lower():
                        error_message = "Gemini API –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω –≤ –≤–∞—à–µ–º —Ä–µ–≥–∏–æ–Ω–µ. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å VPN –∏–ª–∏ –¥—Ä—É–≥–æ–π AI —Å–µ—Ä–≤–∏—Å."
                    elif 'quota' in error_message.lower():
                        error_message = "–ü—Ä–µ–≤—ã—à–µ–Ω–∞ –∫–≤–æ—Ç–∞ Gemini API. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –ø–æ–∑–∂–µ."
                    elif 'invalid' in error_message.lower() and 'key' in error_message.lower():
                        error_message = "–ù–µ–≤–µ—Ä–Ω—ã–π API –∫–ª—é—á Gemini. –ü—Ä–æ–≤–µ—Ä—å—Ç–µ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏."
                    
                    return {
                        'error': error_message,
                        'success': False
                    }
                except:
                    return {
                        'error': f"API request failed with status {response.status_code}",
                        'success': False
                    }
            
            result = response.json()
            
            if 'candidates' not in result or not result['candidates']:
                logger.error("Invalid response from Gemini API: No candidates found")
                return {
                    'error': "Invalid API response: No candidates found",
                    'success': False
                }
            
            first_candidate = result['candidates'][0]
            if 'content' not in first_candidate or 'parts' not in first_candidate['content']:
                logger.error("Invalid response from Gemini API: No content parts found")
                return {
                    'error': "Invalid API response: No content parts found",
                    'success': False
                }
            
            full_analysis_text = ""
            for part in first_candidate['content']['parts']:
                if 'text' in part:
                    full_analysis_text += part['text'] + "\n"
            
            analysis_text = full_analysis_text.strip()
            
            return {
                'success': True,
                'analysis': analysis_text,
                'full_analysis': full_analysis_text.strip(),
                'analysis_type': 'portfolio'
            }
            
        except requests.exceptions.Timeout:
            logger.error("Gemini API request timed out")
            return {
                'error': "Gemini API request timed out",
                'success': False
            }
        except Exception as e:
            logger.error(f"Failed to analyze portfolio with Gemini API: {e}")
            return {
                'error': f"Failed to analyze portfolio: {e}",
                'success': False
            }
    
    def _prepare_portfolio_description(self, portfolio_data: Dict[str, Any]) -> str:
        """
        Prepare comprehensive portfolio description for Gemini analysis
        
        Args:
            portfolio_data: Dictionary containing portfolio-specific data
            
        Returns:
            Formatted portfolio description string
        """
        if not portfolio_data or not isinstance(portfolio_data, dict):
            return "**–û—à–∏–±–∫–∞:** –î–∞–Ω–Ω—ã–µ –ø–æ—Ä—Ç—Ñ–µ–ª—è –Ω–µ–¥–æ—Å—Ç—É–ø–Ω—ã"
        
        description_parts = []
        
        # Basic portfolio info
        if 'symbols' in portfolio_data:
            symbols = portfolio_data['symbols']
            weights = portfolio_data.get('weights', [])
            asset_names = portfolio_data.get('asset_names', {})
            
            # Create portfolio composition
            composition = []
            for i, symbol in enumerate(symbols):
                weight = weights[i] if i < len(weights) else 0
                asset_name = asset_names.get(symbol, symbol)
                composition.append(f"{asset_name}: {weight:.1%}")
            
            description_parts.append(f"**–°–æ—Å—Ç–∞–≤ –ø–æ—Ä—Ç—Ñ–µ–ª—è:** {', '.join(composition)}")
        
        if 'currency' in portfolio_data:
            description_parts.append(f"**–í–∞–ª—é—Ç–∞:** {portfolio_data['currency']}")
        
        if 'period' in portfolio_data:
            description_parts.append(f"**–ü–µ—Ä–∏–æ–¥ –∞–Ω–∞–ª–∏–∑–∞:** {portfolio_data['period']}")
        
        # Portfolio metrics table - –æ—Å–Ω–æ–≤–Ω–∞—è —Ç–∞–±–ª–∏—Ü–∞ –º–µ—Ç—Ä–∏–∫ –ø–æ—Ä—Ç—Ñ–µ–ª—è
        if 'portfolio_metrics_table' in portfolio_data and portfolio_data['portfolio_metrics_table']:
            description_parts.append("\n**üìä –ú–ï–¢–†–ò–ö–ò –ü–û–†–¢–§–ï–õ–Ø:**")
            description_parts.append(portfolio_data['portfolio_metrics_table'])
        
        # Individual assets metrics for comparison
        if 'individual_assets_metrics' in portfolio_data and portfolio_data['individual_assets_metrics']:
            description_parts.append("\n**üìà –ú–ï–¢–†–ò–ö–ò –û–¢–î–ï–õ–¨–ù–´–• –ê–ö–¢–ò–í–û–í (–¥–ª—è —Å—Ä–∞–≤–Ω–µ–Ω–∏—è):**")
            description_parts.append(portfolio_data['individual_assets_metrics'])
        
        # Correlation matrix
        if 'correlations' in portfolio_data and portfolio_data['correlations']:
            description_parts.append("\n**üîó –ö–û–†–†–ï–õ–Ø–¶–ò–û–ù–ù–ê–Ø –ú–ê–¢–†–ò–¶–ê:**")
            symbols = portfolio_data.get('symbols', [])
            asset_names = portfolio_data.get('asset_names', {})
            
            for i, symbol1 in enumerate(symbols):
                for j, symbol2 in enumerate(symbols):
                    if i < j:  # Only upper triangle
                        corr = portfolio_data['correlations'][i][j]
                        
                        # Use asset names if available
                        name1 = asset_names.get(symbol1, symbol1)
                        name2 = asset_names.get(symbol2, symbol2)
                        
                        description_parts.append(f"  ‚Ä¢ {name1} ‚Üî {name2}: {corr:.3f}")
        
        # Efficient frontier data
        if 'efficient_frontier' in portfolio_data and portfolio_data['efficient_frontier']:
            ef_data = portfolio_data['efficient_frontier']
            description_parts.append("\n**üìà –î–ê–ù–ù–´–ï –≠–§–§–ï–ö–¢–ò–í–ù–û–ô –ì–†–ê–ù–ò–¶–´ (okama.EfficientFrontier):**")
            description_parts.append(f"**–í–∞–ª—é—Ç–∞:** {ef_data.get('currency', 'USD')}")
            description_parts.append(f"**–ê–∫—Ç–∏–≤—ã:** {', '.join(ef_data.get('asset_names', []))}")
            
            # Min risk portfolio
            min_risk = ef_data.get('min_risk_portfolio', {})
            if min_risk.get('risk') is not None and min_risk.get('return') is not None:
                description_parts.append(f"\n**üéØ –ü–û–†–¢–§–ï–õ–¨ –ú–ò–ù–ò–ú–ê–õ–¨–ù–û–ì–û –†–ò–°–ö–ê:**")
                description_parts.append(f"  ‚Ä¢ –†–∏—Å–∫: {min_risk['risk']:.2%}")
                description_parts.append(f"  ‚Ä¢ –î–æ—Ö–æ–¥–Ω–æ—Å—Ç—å: {min_risk['return']:.2%}")
                if min_risk.get('weights'):
                    weights_str = []
                    for i, weight in enumerate(min_risk['weights']):
                        asset_name = ef_data.get('asset_names', [])[i] if i < len(ef_data.get('asset_names', [])) else f"Asset_{i}"
                        weights_str.append(f"{asset_name}: {weight:.1%}")
                    description_parts.append(f"  ‚Ä¢ –í–µ—Å–∞: {', '.join(weights_str)}")
            
            # Max return portfolio
            max_return = ef_data.get('max_return_portfolio', {})
            if max_return.get('risk') is not None and max_return.get('return') is not None:
                description_parts.append(f"\n**üöÄ –ü–û–†–¢–§–ï–õ–¨ –ú–ê–ö–°–ò–ú–ê–õ–¨–ù–û–ô –î–û–•–û–î–ù–û–°–¢–ò:**")
                description_parts.append(f"  ‚Ä¢ –†–∏—Å–∫: {max_return['risk']:.2%}")
                description_parts.append(f"  ‚Ä¢ –î–æ—Ö–æ–¥–Ω–æ—Å—Ç—å: {max_return['return']:.2%}")
                if max_return.get('weights'):
                    weights_str = []
                    for i, weight in enumerate(max_return['weights']):
                        asset_name = ef_data.get('asset_names', [])[i] if i < len(ef_data.get('asset_names', [])) else f"Asset_{i}"
                        weights_str.append(f"{asset_name}: {weight:.1%}")
                    description_parts.append(f"  ‚Ä¢ –í–µ—Å–∞: {', '.join(weights_str)}")
            
            # Max Sharpe portfolio
            max_sharpe = ef_data.get('max_sharpe_portfolio', {})
            if max_sharpe.get('risk') is not None and max_sharpe.get('return') is not None:
                description_parts.append(f"\n**‚≠ê –ü–û–†–¢–§–ï–õ–¨ –ú–ê–ö–°–ò–ú–ê–õ–¨–ù–û–ì–û –ö–û–≠–§–§–ò–¶–ò–ï–ù–¢–ê –®–ê–†–ü–ê:**")
                description_parts.append(f"  ‚Ä¢ –†–∏—Å–∫: {max_sharpe['risk']:.2%}")
                description_parts.append(f"  ‚Ä¢ –î–æ—Ö–æ–¥–Ω–æ—Å—Ç—å: {max_sharpe['return']:.2%}")
                description_parts.append(f"  ‚Ä¢ –ö–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç –®–∞—Ä–ø–∞: {max_sharpe.get('sharpe_ratio', 'N/A')}")
                if max_sharpe.get('weights'):
                    weights_str = []
                    for i, weight in enumerate(max_sharpe['weights']):
                        asset_name = ef_data.get('asset_names', [])[i] if i < len(ef_data.get('asset_names', [])) else f"Asset_{i}"
                        weights_str.append(f"{asset_name}: {weight:.1%}")
                    description_parts.append(f"  ‚Ä¢ –í–µ—Å–∞: {', '.join(weights_str)}")
        
        # Additional portfolio info
        if 'additional_info' in portfolio_data and portfolio_data['additional_info']:
            description_parts.append(f"\n**‚ÑπÔ∏è –î–û–ü–û–õ–ù–ò–¢–ï–õ–¨–ù–ê–Ø –ò–ù–§–û–†–ú–ê–¶–ò–Ø:** {portfolio_data['additional_info']}")
        
        # Add instructions for AI
        description_parts.append("\n" + "="*50)
        description_parts.append("**–ò–ù–°–¢–†–£–ö–¶–ò–ò –î–õ–Ø –ê–ù–ê–õ–ò–ó–ê –ü–û–†–¢–§–ï–õ–Ø:**")
        description_parts.append("–ò—Å–ø–æ–ª—å–∑—É–π –≤—Å–µ –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª–µ–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ –¥–ª—è –∫–æ–º–ø–ª–µ–∫—Å–Ω–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞ –ø–æ—Ä—Ç—Ñ–µ–ª—è:")
        description_parts.append("1. –ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É–π –º–µ—Ç—Ä–∏–∫–∏ –ø–æ—Ä—Ç—Ñ–µ–ª—è —Ü–µ–ª–∏–∫–æ–º (CAGR, –≤–æ–ª–∞—Ç–∏–ª—å–Ω–æ—Å—Ç—å, Sharpe, Sortino, –ø—Ä–æ—Å–∞–¥–∫–∏)")
        description_parts.append("2. –°—Ä–∞–≤–Ω–∏ —Ç–µ–∫—É—â–∏–π –ø–æ—Ä—Ç—Ñ–µ–ª—å —Å –æ–ø—Ç–∏–º–∞–ª—å–Ω—ã–º–∏ –ø–æ—Ä—Ç—Ñ–µ–ª—è–º–∏ –∏–∑ —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ–π –≥—Ä–∞–Ω–∏—Ü—ã")
        description_parts.append("3. –û—Ü–µ–Ω–∏ –∫–æ—Ä—Ä–µ–ª—è—Ü–∏–∏ –º–µ–∂–¥—É –∞–∫—Ç–∏–≤–∞–º–∏ –∏ –∫–∞—á–µ—Å—Ç–≤–æ –¥–∏–≤–µ—Ä—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏")
        description_parts.append("4. –î–∞–π –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–µ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –ø–æ —Ä–µ–±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∫–µ —Å —É–∫–∞–∑–∞–Ω–∏–µ–º –Ω–æ–≤—ã—Ö –≤–µ—Å–æ–≤")
        description_parts.append("5. –ü—Ä–µ–¥–ª–æ–∂–∏ —Å—Ç—Ä–∞—Ç–µ–≥–∏—á–µ—Å–∫–∏–µ —É–ª—É—á—à–µ–Ω–∏—è –ø–æ—Ä—Ç—Ñ–µ–ª—è")
        description_parts.append("6. –û—Ü–µ–Ω–∏ —Ä–∏—Å–∫–∏ –∏ –ø—Ä–µ–¥–ª–æ–∂–∏ –º–µ—Ä—ã –ø–æ –∏—Ö —Å–Ω–∏–∂–µ–Ω–∏—é")
        description_parts.append("–î–æ–±–∞–≤—å —é—Ä–∏–¥–∏—á–µ—Å–∫–∏ –ø—Ä–∞–≤–∏–ª—å–Ω—ã–π –¥–∏—Å–∫–ª–µ–π–º–µ—Ä –æ —Ç–æ–º, —á—Ç–æ –∞–Ω–∞–ª–∏–∑ –Ω–µ —è–≤–ª—è–µ—Ç—Å—è –∏–Ω–≤–µ—Å—Ç–∏—Ü–∏–æ–Ω–Ω–æ–π —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–µ–π")
        
        return "\n".join(description_parts)
